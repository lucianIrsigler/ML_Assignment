{
 "cells": [
  {
   "cell_type": "raw",
   "id": "2614f2ae-6ba1-4263-894b-a2c93a6cf249",
   "metadata": {},
   "source": [
    "To see what the data is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1677,
   "id": "15cb9171",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 65\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1678,
   "id": "afe1fe7b-919a-4f33-9c47-183d25bd174d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage\n",
    "import random\n",
    "\n",
    "def displayImage():\n",
    "    with open(\"traindata.txt\",\"r\") as f:\n",
    "        data = f.readlines()\n",
    "        index = random.randint(0,len(data))\n",
    "        index = 3\n",
    "\n",
    "        data = [float(i) for i in data[index].split(',')] # Your list of 1040 grayscale values followed by the rotation angle (as strings)\n",
    "\n",
    "        # Ensure the length of the data list is correct\n",
    "        if len(data) != 1041:\n",
    "            raise ValueError(\"The data list must contain exactly 1041 values, with the last being the rotation angle.\")\n",
    "        \n",
    "        # Separate the pixel values and the rotation angle\n",
    "        rotation_angle = float(data[-1])\n",
    "        pixels = [int(p) for p in data[:-1]]\n",
    "        \n",
    "        # Reshape the pixels array to match the desired dimensions, e.g., 40x26\n",
    "        width, height = 40, 26\n",
    "        image_array = np.array(pixels).reshape((height, width))\n",
    "        \n",
    "        # Apply the rotation to the image\n",
    "        rotated_image = scipy.ndimage.rotate(image_array, rotation_angle, reshape=True)\n",
    "        \n",
    "        # Display the image using Matplotlib\n",
    "        plt.imshow(rotated_image, cmap='gray', vmin=0, vmax=255)\n",
    "        plt.colorbar()  # Optional: adds a colorbar to indicate the scale\n",
    "        plt.title(f\"Grayscale Image {index}(Rotated {rotation_angle} degrees)\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4fcaf2b1-d43e-4898-ba3b-6b9a4b28ea35",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "The dataset:\n",
    "1041 features\n",
    "1040 pixels\n",
    "1 rotation(last feature)\n",
    "\n",
    "5250 inputs\n",
    "\n",
    "Training labels are [0,20]\n",
    "\n",
    "Only rotations are [0,1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1679,
   "id": "bce1ad6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hot_one_encoding(number):\n",
    "    nums = [0]*4\n",
    "    nums[number]=1\n",
    "    return nums\n",
    "\n",
    "def min_max_scale(trainData,trainLabels):\n",
    "    pixel_arrays = []\n",
    "    pixels_labels = []\n",
    "\n",
    "    for i in range(len(trainData)):\n",
    "        pixels = list(map(float,trainData[i]))\n",
    "        rotation_angle = pixels.pop()\n",
    "        hotOneEncoding = hot_one_encoding(int(rotation_angle))\n",
    "\n",
    "        min_val = min(pixels)\n",
    "        max_val = max(pixels)\n",
    "        \n",
    "        for j in range(len(pixels)):\n",
    "            pixels[j] = (pixels[j]-min_val)/(max_val-min_val)\n",
    "\n",
    "        for j in hotOneEncoding:\n",
    "            pixels.append(j)\n",
    "\n",
    "        pixel_arrays.append(pixels)\n",
    "        pixels_labels.append(int(trainLabels[i]))\n",
    "\n",
    "    inputData = np.array(pixel_arrays)\n",
    "    inputLabels = np.array(pixels_labels)\n",
    "\n",
    "    return inputData,inputLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1680,
   "id": "ba9fa76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"traindata.txt\",\"r\") as f:\n",
    "    trainData = [i.split(\",\") for i in f.readlines()]\n",
    "\n",
    "with open(\"trainlabels.txt\",\"r\") as f:\n",
    "    trainLabels = f.readlines()\n",
    "\n",
    "inputData,inputLabels = min_max_scale(trainData,trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1681,
   "id": "87adb998",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_temp,y_train,y_temp = train_test_split(inputData,inputLabels,test_size=0.3,random_state=seed)\n",
    "x_test, x_val,y_test,y_val, = train_test_split(x_temp,y_temp, test_size=0.5, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1682,
   "id": "c20847b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1683,
   "id": "fcbc4d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainingCount():\n",
    "    count = {i:0 for i in range(21)}\n",
    "\n",
    "    for i in y_train:\n",
    "        count[int(i)]+=1\n",
    "\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1684,
   "id": "b435c82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7fc3d525f0>"
      ]
     },
     "execution_count": 1684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1685,
   "id": "0c8a563d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1686,
   "id": "6b2a6a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor(x_train)\n",
    "x_test = torch.FloatTensor(x_test)\n",
    "x_val = torch.FloatTensor(x_val)\n",
    "\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_val = torch.LongTensor(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1687,
   "id": "137cc3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "#torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1688,
   "id": "fd463c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    #h1=512,h2=128,out=21 => 60% with dropout of 50% ;in was 1044\n",
    "    def __init__(self,in_features=1044,h1=512,h2=128,out=21):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(in_features,h1),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(h1,h2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "\n",
    "        self.outlayer = nn.Linear(h2,out)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.outlayer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1689,
   "id": "b4eb05f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "config = {\n",
    "    \"epochs\":1000,\n",
    "    \"checkInterval\":5,\n",
    "    \"printInterval\":30,\n",
    "    \"patience\":30\n",
    "}\n",
    "\n",
    "outputConfig = {\n",
    "    \"maxEpochs\":1000,\n",
    "    \"losses\": []\n",
    "}\n",
    "\n",
    "def train(newModel,canPrint=False):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(newModel.parameters(),lr=learning_rate)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    no_improvement_count = 0\n",
    "    temp_losses = []\n",
    "    temp_epoch = 1000\n",
    "\n",
    "    best_model_state = newModel.state_dict()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        newModel.train()\n",
    "        y_pred = newModel(x_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        temp_losses.append(loss.item())  # Append the loss value as a Python scalar\n",
    "        if (epoch % config[\"printInterval\"] == 0 and canPrint == True):\n",
    "            print(f\"Epoch: {epoch} and loss: {loss.item()}\\t No improvement:{no_improvement_count}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if (epoch % config[\"checkInterval\"] == 0):\n",
    "            newModel.eval()\n",
    "            with torch.no_grad():\n",
    "                y_val_pred = newModel(x_val)\n",
    "                val_loss = criterion(y_val_pred, y_val)\n",
    "                \n",
    "                if val_loss.item() < best_val_loss:\n",
    "                    best_val_loss = val_loss.item()\n",
    "                    no_improvement_count = 0  # Reset the no improvement count\n",
    "                    best_model_state = newModel.state_dict()\n",
    "                else:\n",
    "                    no_improvement_count += 1\n",
    "                    \n",
    "                    if no_improvement_count >= config[\"patience\"]:\n",
    "                        temp_epoch = epoch\n",
    "                        newModel.load_state_dict(best_model_state)\n",
    "                        break\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "    if (canPrint==True):\n",
    "        print(f\"Best epoch: {temp_epoch}\")\n",
    "    \n",
    "    outputConfig[\"losses\"] = temp_losses\n",
    "    outputConfig[\"maxEpochs\"] = temp_epoch\n",
    "    return newModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1690,
   "id": "8df0d6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(newModel):\n",
    "    newModel= train(newModel,False)\n",
    "    return newModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1691,
   "id": "5e9586b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph out loss for model\n",
    "def graph():\n",
    "    plt.plot(range(outputConfig[\"maxEpochs\"]),outputConfig[\"losses\"])\n",
    "    plt.ylabel(\"loss/error\")\n",
    "    plt.xlabel(\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1692,
   "id": "e55f8fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "incorrect = {i: 0 for i in range(21)}  # Initialize the nested dictionary\n",
    "\n",
    "def correct(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_val = model.forward(x_test)\n",
    "        for i in range(len(y_test)):\n",
    "            predicted_label = y_val[i].argmax().item()\n",
    "            true_label = y_test[i].item()\n",
    "\n",
    "            if predicted_label == true_label:\n",
    "                correct += 1\n",
    "            else:\n",
    "                incorrect[true_label] += 1\n",
    "\n",
    "    accuracy = correct / len(y_test)\n",
    "    return accuracy\n",
    "\n",
    "def saveIncorrectToJSON(): \n",
    "    with open('incorrect_predictions.json', 'w') as json_file:\n",
    "        json.dump(incorrect, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1695,
   "id": "de241b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5667090216010165\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "newModel = Model()\n",
    "optimizer = torch.optim.Adam(newModel.parameters(),lr=learning_rate)\n",
    "newModel = trainModel(newModel)\n",
    "accuracy = correct(newModel)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3960b696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testMultiple():\n",
    "    in_features_const = 1044\n",
    "    #h1:h2\n",
    "    layers = [\n",
    "        (520, 256),\n",
    "        (512, 256), (512, 128), (512, 64), (512, 32),\n",
    "        (256, 128), (256, 64), (256, 32),\n",
    "        (128, 64), (128, 32),\n",
    "        (64, 32),\n",
    "        (1024, 512), (1024, 256), (1024, 128),\n",
    "        (512, 512), (512, 1024),\n",
    "        (256, 512), (256, 256),\n",
    "        (128, 128), (128, 256),\n",
    "        (64, 128), (64, 64),\n",
    "        (32, 64), (32, 32)\n",
    "    ]\n",
    "\n",
    "    for i in layers:\n",
    "        h1 = i[0]\n",
    "        h2 = i[1]\n",
    "        print(f\"h1:{h1} and h2:{h2}\")\n",
    "        newModel = Model(in_features_const,h1,h2)\n",
    "        newModel = trainModel(newModel)\n",
    "        correct(newModel)\n",
    "\n",
    "#testMultiple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8500699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "def save(model):\n",
    "    torch.save(model.state_dict(),\"classify.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
